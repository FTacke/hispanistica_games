---
title: "How-To: JSON Annotation Workflow"
status: active
owner: backend-team
updated: "2025-11-08"
tags: [how-to, annotation, workflow, json, nlp]
links:
  - ../reference/json-annotation-v2-specification.md
  - ../reference/corpus-search-architecture.md
  - ../operations/database-creation.md
---

# How-To: JSON Annotation Workflow

Praktische Anleitung zur Annotation von CO.RA.PAN Transkripten mit v2-Schema.

---

## Ziel

Nach dieser Anleitung k√∂nnen Sie:
- ‚úÖ JSON-Transkripte mit linguistischen Annotationen versehen
- ‚úÖ Idempotente Re-L√§ufe durchf√ºhren
- ‚úÖ Zeitformen robust erkennen (Perfekt, analytisches Futur)
- ‚úÖ Annotationen validieren und statistisch auswerten

---

## Voraussetzungen

### Software

- Python 3.9+
- spaCy 3.x
- Spanisches spaCy-Modell: `es_dep_news_trf`

### Installation

```powershell
# Virtual Environment aktivieren
.\.venv\Scripts\Activate.ps1

# spaCy-Modell installieren (falls noch nicht vorhanden)
python -m spacy download es_dep_news_trf
```

### Datenstruktur

```
media/
  transcripts/
    ARG/
      001.json
      002.json
      ...
    BOL/
      001.json
      ...
    CHI/
      ...
```

---

## Schritte

### Schritt 1: Backup erstellen (empfohlen)

Vor der ersten Annotation oder bei Force-Modus:

```powershell
# Backup-Ordner erstellen
New-Item -ItemType Directory -Path "media\transcripts_backup_$(Get-Date -Format 'yyyyMMdd_HHmmss')"

# Alle JSON-Dateien kopieren
Copy-Item -Path "media\transcripts\*\*.json" -Destination "media\transcripts_backup_*" -Recurse
```

**Wichtig:** Bei v1‚Üív2 Migration werden alte Annotationen √ºberschrieben!

---

### Schritt 2: Script ausf√ºhren

**Navigiere zum Script-Ordner:**
```powershell
cd "LOKAL\01 - Add New Transcriptions\02 annotate JSON"
```

#### Option A: Safe-Modus (Standard, empfohlen)

Nur ge√§nderte/neue Dateien annotieren:

```powershell
python annotation_json_in_media_v2.py safe
```

**Ablauf:**
1. Script fragt: `[all]` oder `[Zahl]`
2. Eingabe: `all` (alle Dateien) oder z.B. `5` (erste 5 Dateien)
3. Script analysiert Dateien (Idempotenz-Check)
4. Zeigt √úbersicht: X zu annotieren, Y √ºbersprungen
5. Annotiert nur notwendige Dateien

**Wann nutzen:**
- ‚úÖ Regul√§re Re-L√§ufe
- ‚úÖ Nach Content-√Ñnderungen
- ‚úÖ Fehlende Felder erg√§nzen

#### Option B: Force-Modus

Alle Dateien neu annotieren (ignoriert Idempotenz):

```powershell
python annotation_json_in_media_v2.py force
```

**Wann nutzen:**
- ‚ö†Ô∏è Nach spaCy-Modell-Update
- ‚ö†Ô∏è Nach Script-√Ñnderungen (z.B. Zeitformen-Regeln)
- ‚ö†Ô∏è Validierung/Debugging

**Warnung:** Kann mehrere Stunden dauern bei gro√üem Korpus!

---

### Schritt 3: Fortschritt verfolgen

**Output-Beispiel:**

```
üîß Modus: SAFE
üìÅ Gefunden: 156 JSON-Dateien

üîç Analysiere Dateien (Idempotenz-Check)...

üìä ANNOTATIONS√úBERSICHT
   Zu annotieren:  12 Dateien (45,230 W√∂rter)
   √úbersprungen:   144 Dateien

   Gr√ºnde f√ºr √úbersprungen:
      ‚Ä¢ up-to-date: 144 Dateien

üìÑ [1/12] ARG/001.json
   ‚îî‚îÄ 3,850 W√∂rter | Grund: missing fields: norm, token_id, sentence_id...
   ‚îú‚îÄ Fortschritt: 2,500 / 45,230 W√∂rter (5.5%)
   ‚îú‚îÄ Fortschritt: 3,850 / 45,230 W√∂rter (8.5%)
   ‚îî‚îÄ ‚úì ARG/001.json (annotated)
```

**Symbole:**
- `‚úì` = Erfolgreich annotiert
- `‚äô` = √úbersprungen (bereits aktuell)
- `‚úó` = Fehler

---

### Schritt 4: Validierung

#### A) Metadaten pr√ºfen

√ñffne eine annotierte Datei:

```powershell
code "media\transcripts\ARG\001.json"
```

**Erwartete Struktur (Top-Level):**

```json
{
  "ann_meta": {
    "version": "corapan-ann/v2",
    "spacy_model": "es_dep_news_trf",
    "text_hash": "a1b2c3d4e5...",
    "required": ["token_id", "sentence_id", ...],
    "timestamp": "2025-11-08T14:30:00+00:00"
  },
  "segments": [...]
}
```

#### B) Token-Felder pr√ºfen

**Erwartete Token-Struktur:**

```json
{
  "text": "cantado",
  "start": 1.2,
  "end": 1.5,
  "token_id": "ARG_001:0:0:5",
  "sentence_id": "ARG_001:0:s0",
  "utterance_id": "ARG_001:0",
  "start_ms": 1200,
  "end_ms": 1500,
  "lemma": "cantar",
  "pos": "VERB",
  "dep": "ROOT",
  "head_text": "cantado",
  "morph": {
    "VerbForm": ["Part"],
    "Tense": ["Past"],
    "Past_Tense_Type": "PerfectoCompuesto"
  },
  "norm": "cantado",
  "past_type": "PerfectoCompuesto",
  "future_type": ""
}
```

#### C) Smoke-Tests (manuelle Suche)

Suche nach typischen Konstruktionen in JSON-Dateien:

| Suche nach | Erwartetes Label | Feld |
|------------|------------------|------|
| `"ha cantado"` | `PerfectoCompuesto` | `past_type` |
| `"hab√≠a cantado"` | `Pluscuamperfecto` | `past_type` |
| `"voy a cantar"` | `analyticalFuture` | `future_type` |
| `"iba a cantar"` | `analyticalFuture_past` | `future_type` |

**Beispiel (VS Code Search):**
1. `Ctrl+Shift+F` (Suche in Dateien)
2. Suche: `"text": "cantado"`
3. Pr√ºfe `past_type` Feld im gleichen Token-Objekt

#### D) Statistik-Ausgabe pr√ºfen

Am Ende des Laufs zeigt das Script automatisch:

```
üìä ZEITFORMEN-STATISTIKEN (aus annotierten Dateien)
   Tokens analysiert: 50,000

   üïê Vergangenheitsformen:
      ‚Ä¢ PerfectoSimple          3,456 (6.91%)
      ‚Ä¢ PerfectoCompuesto        1,234 (2.47%)
      ‚Ä¢ Pluscuamperfecto          234 (0.47%)
      ‚Ä¢ FuturoPerfecto             12 (0.02%)
      ‚Ä¢ CondicionalPerfecto         5 (0.01%)

   üïë Zukunftsformen:
      ‚Ä¢ analyticalFuture          567 (1.13%)
      ‚Ä¢ analyticalFuture_past      89 (0.18%)
```

**Sanity-Checks:**
- ‚úÖ PerfectoSimple sollte h√§ufigster Wert sein
- ‚úÖ PerfectoCompuesto sollte 2-5% der Tokens sein
- ‚úÖ analyticalFuture sollte 1-2% sein
- ‚ö†Ô∏è Wenn alle Werte 0: Script-Problem!

---

### Schritt 5: Fehlerbehandlung

#### Fehler: spaCy-Modell nicht gefunden

```
‚ùå Can't find model 'es_dep_news_trf'
```

**L√∂sung:**
```powershell
python -m spacy download es_dep_news_trf
```

#### Fehler: Alte v1-Imports

```
‚ùå "PRESENT_FORMS" is not defined
```

**L√∂sung:** Nutze `annotation_json_in_media_v2.py` (nicht v1!)

#### Fehler: Datei-Encoding

```
‚ùå UnicodeDecodeError: 'charmap' codec can't decode...
```

**L√∂sung:** Script nutzt automatisch `utf-8`. Falls Problem besteht:
```python
# In Script √§ndern:
open(file, "r", encoding="utf-8")
```

#### Einzelne Datei √ºberspringen

Falls eine Datei Probleme macht:

1. **Tempor√§r entfernen:**
   ```powershell
   Move-Item "media\transcripts\ARG\problematic.json" "media\transcripts\problematic_temp.json"
   ```

2. **Annotation durchf√ºhren**

3. **Datei zur√ºck und einzeln debuggen:**
   ```powershell
   Move-Item "media\transcripts\problematic_temp.json" "media\transcripts\ARG\problematic.json"
   ```

---

### Schritt 6: Re-Runs (Idempotenz)

**Szenario:** Einige Dateien haben neuen Content

```powershell
# Safe-Modus l√§uft automatisch nur neue/ge√§nderte Dateien
python annotation_json_in_media_v2.py safe
# Eingabe: all
```

**Erwartetes Verhalten:**
- ‚úÖ Dateien mit gleichem `text_hash` werden √ºbersprungen
- ‚úÖ Nur ge√§nderte Dateien werden annotiert
- ‚úÖ Neue Dateien werden vollst√§ndig annotiert

**Log:**
```
   Gr√ºnde f√ºr √úbersprungen:
      ‚Ä¢ up-to-date: 144 Dateien
      ‚Ä¢ text changed: 8 Dateien  ‚Üí werden annotiert
      ‚Ä¢ missing fields: 4 Dateien ‚Üí werden annotiert
```

---

## Validierungs-Checklist

Nach jedem Lauf:

- [ ] `ann_meta.version == "corapan-ann/v2"`
- [ ] `ann_meta.text_hash` vorhanden (40 Zeichen SHA1)
- [ ] `ann_meta.timestamp` im ISO-8601 Format
- [ ] Alle Tokens haben `token_id` (Format: `COUNTRY_FILE:UTT:SENT:TOKEN`)
- [ ] Alle Tokens haben `sentence_id` (Format: `COUNTRY_FILE:UTT:sSENT`)
- [ ] Alle Tokens haben `start_ms`/`end_ms` (Integer)
- [ ] Alle Tokens haben `norm` (lowercase, ohne Akzente au√üer √±)
- [ ] Alle Tokens haben `past_type`/`future_type` (kann leer sein)
- [ ] Alle Segmente haben `utt_start_ms`/`utt_end_ms`
- [ ] Statistik zeigt plausible Werte (PerfectoSimple > 5%)

---

## Rollback

Falls Annotation fehlschl√§gt oder unerw√ºnschte Ergebnisse:

```powershell
# Backup wiederherstellen
Remove-Item -Path "media\transcripts" -Recurse
Copy-Item -Path "media\transcripts_backup_YYYYMMDD_HHmmss" -Destination "media\transcripts" -Recurse
```

---

## Performance-Tipps

### Kleine Test-L√§ufe

Vor vollst√§ndigem Lauf auf Sample testen:

```powershell
python annotation_json_in_media_v2.py safe
# Eingabe: 5  (nur erste 5 Dateien)
```

### Parallele Verarbeitung (fortgeschritten)

F√ºr sehr gro√üe Korpora:

```powershell
# Split nach L√§ndern und parallel verarbeiten (manuell)
# Terminal 1:
python annotation_json_in_media_v2.py safe  # Nur ARG/BOL/CHI ausw√§hlen

# Terminal 2:
python annotation_json_in_media_v2.py safe  # Nur COL/CRI/etc. ausw√§hlen
```

**Achtung:** Erfordert manuelle Selektion!

### Monitoring

Bei gro√üen L√§ufen:

```powershell
# Fortschritt verfolgen
Get-Content "annotation.log" -Wait  # Falls Logging implementiert
```

---

## Integration mit nachfolgenden Steps

### ‚Üí Database Creation

Nach erfolgreicher Annotation:

```powershell
cd "..\03 update DB"
python database_creation_v2.py
```

**Nutzt automatisch:**
- ‚úÖ `token_id` f√ºr eindeutige Token-Referenzen
- ‚úÖ `norm` f√ºr Suchindex
- ‚úÖ `past_type`/`future_type` f√ºr Filter
- ‚úÖ `start_ms`/`end_ms` f√ºr Timeline

### ‚Üí Corpus Search

Nach DB-Import:

```python
# In Search-Backend
WHERE norm LIKE '%cantado%'
  AND past_type = 'PerfectoCompuesto'
```

---

## Pr√§vention

### Vor jedem Lauf

1. **Backup** (bei Force-Modus)
2. **Git Commit** der aktuellen JSONs (falls versioniert)
3. **Test auf Sample** (erste 5 Dateien)

### Regelm√§√üige Wartung

- **Monatlich:** Idempotenz-Check auf allen Dateien (`safe` Modus)
- **Nach Content-Updates:** Re-Annotation betroffener Dateien
- **Nach spaCy-Update:** Force-Modus auf kompletten Korpus

---

## Troubleshooting-Guide

| Problem | Diagnose | L√∂sung |
|---------|----------|--------|
| **Alle Dateien √ºbersprungen** | `up-to-date` | Normal! Keine Aktion n√∂tig |
| **Keine Zeitformen erkannt** | Statistik zeigt 0% | Pr√ºfe spaCy-Modell, Force-Modus testen |
| **Zu viele False Positives** | PerfectoCompuesto bei Nomen | Bug! Report an Dev-Team |
| **Langsame Performance** | >1 Min pro 1000 Tokens | Normal bei `es_dep_news_trf` (Transformer) |
| **Out of Memory** | RAM >8GB | Kleinere Batches (z.B. 10 Dateien) |

---

## Siehe auch

- [JSON Annotation v2 Specification](../reference/json-annotation-v2-specification.md) - Vollst√§ndige Schema-Dokumentation
- [Corpus Search Architecture](../reference/corpus-search-architecture.md) - Integration mit Such-Backend
- [Database Creation](../operations/database-creation.md) - DB-Import nach Annotation
- [spaCy Spanish Models](https://spacy.io/models/es) - Modell-Dokumentation
